{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.getenv(\"GEMINI_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI uses algorithms to learn from data and make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hell', 'shit', 'ass', 'dumbass']\n"
     ]
    }
   ],
   "source": [
    "# First test the code with a single json file\n",
    "\n",
    "with open(\"All_Conversations/c67274cc-d920-467a-80cc-476c9dd280d4.json\", \"r\") as f:\n",
    "    conversation = f.read()\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are a helpful assistant. Your task is to identify any profane words in the conversation below.\n",
    "    If you find any, please list them. If there are no profane words, respond with a blank list.\n",
    "\n",
    "    Give output strictly in the form of a python list:\n",
    "    [\"word1\", \"word2\", ...]\n",
    "    or [] if there are no profane words.\n",
    "\n",
    "    Only return the list and nothing else.\n",
    "\n",
    "    Here is the conversation:\n",
    "    \"\"\" + conversation\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt,\n",
    "    )\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file c67274cc-d920-467a-80cc-476c9dd280d4.json: invalid syntax (<string>, line 1)\n"
     ]
    }
   ],
   "source": [
    "# read json files from All_Conversations\n",
    "# make api calls sending json content and asking it to detect all profane words from the conversation\n",
    "# pause for 3 seconds between each call to avoid rate limit\n",
    "\n",
    "# each json file has content as follows\n",
    "# Each json file is a conversation with multiple messages structured as follows\n",
    "# [\n",
    "#     {\n",
    "#         \"speaker\": \"Agent\",\n",
    "#         \"text\": \"Hello, is this Mr. Johnson? This is Lisa calling from XYZ Collections. How are you today?\",\n",
    "#         \"stime\": 0,\n",
    "#         \"etime\": 7\n",
    "#     },\n",
    "#     {\n",
    "#         \"speaker\": \"Customer\",\n",
    "#         \"text\": \"I'm sorry, but I think you have the wrong person. My name is Sarah.\",\n",
    "#         \"stime\": 6.5,\n",
    "#         \"etime\": 12\n",
    "#     },\n",
    "#     {\n",
    "#         \"speaker\": \"Agent\",\n",
    "#         \"text\": \"Oh, I apologize for the confusion, Sarah. I'm reaching out about a debt related to an outstanding balance with Definite Bank.\",\n",
    "#         \"stime\": 11,\n",
    "#         \"etime\": 19\n",
    "#     },\n",
    "#     {\n",
    "#         \"speaker\": \"Customer\",\n",
    "#         \"text\": \"I don't have any account with Definite Bank. You might want to check your records.\",\n",
    "#         \"stime\": 18,\n",
    "#         \"etime\": 24\n",
    "#     },\n",
    "#     {\n",
    "#         \"speaker\": \"Agent\",\n",
    "#         \"text\": \"Thank you for letting me know. I will make a note to update our records.\",\n",
    "#         \"stime\": 23,\n",
    "#         \"etime\": 30\n",
    "#     },\n",
    "#     {\n",
    "#         \"speaker\": \"Customer\",\n",
    "#         \"text\": \"I appreciate that. Is there anything else I need to do?\",\n",
    "#         \"stime\": 29,\n",
    "#         \"etime\": 34\n",
    "#     },\n",
    "#     {\n",
    "#         \"speaker\": \"Agent\",\n",
    "#         \"text\": \"No, that's all. I'm sorry for any inconvenience caused. Have a great day!\",\n",
    "#         \"stime\": 33,\n",
    "#         \"etime\": 40\n",
    "#     },\n",
    "#     {\n",
    "#         \"speaker\": \"Customer\",\n",
    "#         \"text\": \"Thank you, you too!\",\n",
    "#         \"stime\": 39,\n",
    "#         \"etime\": 42\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# make profane_words a set\n",
    "profane_words = set()\n",
    "\n",
    "for file in os.listdir(\"All_Conversations\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(\"All_Conversations\", file), \"r\") as f:\n",
    "            conversation = f.read()\n",
    "\n",
    "            prompt = \"\"\"\n",
    "            You are a helpful assistant. Your task is to identify any profane words in the conversation below.\n",
    "            If you find any, please list them. If there are no profane words, respond with a blank list.\n",
    "\n",
    "            Give output strictly in the form of a python list:\n",
    "            [\"word1\", \"word2\", ...]\n",
    "            or [] if there are no profane words.\n",
    "\n",
    "            Only return the list and nothing else.\n",
    "\n",
    "            Here is the conversation:\n",
    "            \"\"\" + conversation\n",
    "\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=prompt,\n",
    "            )\n",
    "\n",
    "            # trust that the response is a valid list and push the response to profane_words\n",
    "            try:\n",
    "                words = eval(response.text)\n",
    "                if isinstance(words, list):\n",
    "                    # add the words to the set\n",
    "                    for word in words:\n",
    "                        if isinstance(word, str):\n",
    "                            profane_words.add(word.strip())\n",
    "                else:\n",
    "                    print(f\"Unexpected response format for file {file}: {response.text}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "            time.sleep(3) # to prevent rate limit issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profane words found in the conversations:\n",
      "['f***ing', 'crap', 'BS', 'fuck', 'dead', 'joke', 'f******', 'F***', 'idiots', 'goddamn', 'Screw', 'f**k', 'screwed', 'ass', 'jerking', 'a**', 'sick', 'damn', 'shit', 'idiot', 'bullshit', 'hell', 'pissing', 'shove', 'stupid', 'assholes', 'screw', 'bullsh*t', 'sh*t', 's***', 'freaking', 's**t', 'shitload', 'f***']\n"
     ]
    }
   ],
   "source": [
    "profane_words = list(profane_words)\n",
    "print(\"Profane words found in the conversations:\")\n",
    "print(profane_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "profane_words = set([\n",
    "    'fucking', 'crap', 'BS', 'fuck', 'dead', 'joke',\n",
    "    'idiots', 'goddamn', 'screw', 'fuck', 'screwed', 'ass', 'jerking',\n",
    "    'sick', 'damn', 'shit', 'idiot', 'bullshit', 'hell', 'pissing',\n",
    "    'shove', 'stupid', 'assholes', 'screw', 'bullshit',\n",
    "    'freaking', 'shitload', 'dumbass'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BS',\n",
       " 'crap',\n",
       " 'fuck',\n",
       " 'dead',\n",
       " 'joke',\n",
       " 'idiots',\n",
       " 'goddamn',\n",
       " 'screwed',\n",
       " 'ass',\n",
       " 'jerking',\n",
       " 'sick',\n",
       " 'damn',\n",
       " 'shit',\n",
       " 'idiot',\n",
       " 'bullshit',\n",
       " 'hell',\n",
       " 'pissing',\n",
       " 'shove',\n",
       " 'stupid',\n",
       " 'assholes',\n",
       " 'fucking',\n",
       " 'screw',\n",
       " 'freaking',\n",
       " 'shitload',\n",
       " 'dumbass']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(profane_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profane words list has been extracted using LLM to be used with regex match as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
